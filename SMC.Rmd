---
title: "SMC"
author: "Ant Stephenson, Shannon Williams"
date: "5/25/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This document provides a (very) brief overview of Sequential Monte Carlo (SMC) methods and Stochastic Volatility (SV) models alongside an implementation in both `R` and `Rcpp` to demonstrate state (and parameter) estimation in this context. We start by introducing SMC, followed by a similar introduction of SV models. This leads us on to demonstrate our implementation(s) of a bootstrap particle filter for state estimation, before finally an implementation of the SMC^2 algorithm, which simultaneously estimates the parameters and the states. 

## Sequential Monte Carlo

Sequential Monte Carlo methods refer to a set of simulation-based filtering algorithms that enable us to compute posterior distributions for Bayesian state-space models (among others). SMC methods include *particle filters* in their various guises and extend Bayesian filtering capabilities beyond the widely known *Kalman* filter (and its own extensions) to nonlinear, non-Gaussian models.

## Stochastic Volatility Models

Generally, Stochastic Volatility (SV) models refer to financial models of log-returns ($Y_t=\log(p_t/p_{t-1})$) where the volatility is taken to be a stochastic process. This is as opposed to deterministic models such as (G)ARCH ([Generalised] auto-regressive conditional heteroscedastic). 

The model we shall use here is the following
$$ 
  Y_t|X_t=x_t\sim\mathcal{N}(0,\exp(x_t))
$$
where $\{X_t\}$ is an auto-regressive process following
$$
  X_t = \mu + \rho(X_{t-1} - \mu) + U_t
$$
with $U_t\sim\mathcal{N}(0, \sigma^2)$. 

### Data Generation

We define a function to generate data according to the SV model:
```{r, cache=TRUE, code=xfun::read_utf8('R/generateSVmodel.R'), gensv}
```

### Implementation

To model the latent variables in the SV model we implement a bootstrap particle filter in `R`. To aid further generalisation, we define an API using an OOP approach, by defining a framework based around the Feynman-Kac formalism and implementing a specific class for the SV model. The particle filter then relies only on the Feynman-Kac structure and could in principle take any object implementing that API (though here we only implement the specific SV class).

```{r, cache=TRUE, code=xfun::read_utf8('R/Bootstrap_SV.R'), bootR}
```

and additionally in `C++` making use of the `Rcpp` package in order to make simulations more computationally manageable. We go on to test that a) the results match (excluding variations due to unset random seeds in C++) and b) that the C++ implementation is indeed faster than in `R`. We aim to replicate the API defined in the `R` code above in `Rcpp` for ease of use.

```{Rcpp, eval=FALSE, cache=TRUE, code=xfun::read_utf8('src/particles.cpp'), particles}
```

First generate some data according to the SV model.
```{r, test}
library(smc)
library(Rcpp)

set.seed(1)

tmax <- 500
mu <- -1
rho <- 0.95
sigma <- 0.15
N <- 5000

Xt <- generate_SV_data(mu, rho, sigma, tmax)
Yt <- as.matrix(rnorm(tmax, mean = 0, sd = sqrt(exp(Xt))))
```

Run the `R` particle filter implementation, by first instantiating an SV object with given parameters and then running this through the bootstrap PF.
```{r, RPF}
boot_sv <- Bootstrap_SV$new(data = Yt, mu = -1, sigma = 0.15, rho = 0.95)

output <- bootstrap_filter(boot_sv, N, tmax)
```

For the `Rcpp` version we must load the associated package exposed to `R`, initialise the `Rcpp` exposed class and then run the particle filter. 
```{r, RcppPF}
Bootstrap_SV_C <- Bootstrap_SV_C
boot_sv_rcpp <- new(Bootstrap_SV_C, Yt, -1, 0.15, 0.95)
output2 <- bootstrap_filter_rcpp(boot_sv_rcpp, N ,tmax)
```

Plot the mean outputs from the R and Rcpp versions over the true latent variable. We see that the `Rcpp` version (in green) is more or less identical to the (red) `R` version. The difference we attribute to random seeds.
```{r, plot}
library(latex2exp)
pdf("docs/figs/state_estimation_pf.pdf", width=8, height=3)
par(mar=c(4,4,1,4))
par(mfrow = c(1,2))
plot(Xt, type = "l", ylab=TeX("$X_t$"), main="", xlab="t")
lines(output$mx, col = "red")
lines(output2$mx, col="green")
legend("bottomleft", legend=c("R", "Rcpp"))
plot(1:tmax, output$ess, type = "l", ylab="ESS", xlab="t")
dev.off()

# Delete the outputs to avoid running out of memory
rm(output)
rm(output2)
gc()
```

We now verify that the `Rcpp` version is faster than the `R` implementation using the `microbenchmark` package:
```{r, bench}
library(microbenchmark)

run_filter <- function(filter_fn, ...) {
  out <- filter_fn(...)
  rm(out)
  gc()
  return(NA)
}
funcs <- c(call("run_filter", bootstrap_filter, boot_sv, N, tmax), call("run_filter", bootstrap_filter_rcpp, boot_sv_rcpp, N, tmax))

bench_res <- microbenchmark(list=setNames(funcs, c("R","Rcpp")),
               times=5L)

print(bench_res, signif=3)
```

## SMC^2

The particle filter implementation above relies on knowing the parameters $\sigma^2, \rho, \mu$ *a priori*. Of course, this is not likely in any realistic scenario, so we must be able to estimate these parameters as well. Here we choose to implement the SMC^2 algorithm to simultaneously estimate the parameters alongside state estimation with the particle filter.

We run the SMC^2 algorithm to estimate the parameters $\mu$ and $\sigma$, using a Gaussian random walk proposal for both $\mu$ and $\sigma$. Since parameter estimation means we have an effective burn-in for state estimation, we choose to take the final parameters from the SMC^2 results and use them in an additional bootstrap filtering step. 

We start by estimating only the $\mu$ parameter, before attempting to extend to $\sigma$. We choose to avoid attempting to estimate $\rho$ due to computational difficulties associated with the tight prior needed to constrain the values to something close to (but less than or equal to) 1. This seems reasonable for the kind of SV setting we are considering due to the generally accepted assumption that it be so constrained that an assumed value close to 1 will suffice.

```{r,smc2}
tmax <- 1000
mu <- -0.99
rho <- 0.95
sigma <- 0.15
Xt <- generate_SV_data(mu, rho, sigma, tmax)
Yt <- as.matrix(rnorm(tmax+1, mean = 0, sd = sqrt(exp(Xt))))
Nx <- 500
Nt <- 200
mu_prior <- -0.5
sd_prior <- 0.3
sd_prop <- 0.5
smc_results <- smc_squared_rcpp(Yt, Nx, Nt, sigma, rho, 
                                mu_prior = mu_prior, sd_prior = sd_prior, sd_prop =sd_prop)
thetas <- smc_results$thetas
Wm <- smc_results$Wm
rm(smc_results)
```

Before we run the bootstrap filter again, first analyse the output from SMC^2. We start by plotting the convergence of the parameters:
```{r, smc2 out}
pdf("docs/figs/param_estimation_smc2.pdf", width=8, height=3)
par(mar=c(4,4,1,4))
par(mfrow = c(1,1))
plot(rowMeans(thetas), ylab=TeX("$\\mu$"), type="l", xlab="t")
lines(rep(mu, tmax+1), col="red")
dev.off()
```

We now try to extend the SMC^2 implementation to $\sigma$.
```{r, smc22}
tmax <- 1000
mu <- -1
rho <- 0.95
sigma <- 0.15
Xt <- generate_SV_data(mu, rho, sigma, tmax)
Yt <- as.matrix(rnorm(tmax+1, mean = 0, sd = sqrt(exp(Xt))))
Nx <- 500
Nt <- 200

mu_prior = c(-0.5, 0.2)
sigma_prior <- c(2, 2)
sd_prop <- c(0.5, 1.0)

smc_results2 <- smc_squared_rcpp2(Yt, Nx, Nt, sigma, rho, 
                           mu_prior = mu_prior, sigma_prior = sigma_prior, sd_prop = sd_prop)
thetas2 <- smc_results2$thetas
Wm2 <- smc_results2$Wm
rm(smc_results2)
```

Again we plot the convergence of the parameters, as we did for the single parameter version.
```{r, smc22 out}
pdf("docs/figs/param_estimation_smc22.pdf", width=8, height=3)
par(mar=c(4,4,1,4))
par(mfrow = c(1,2))
plot(rowMeans(thetas2[,,1]), ylab=TeX("$\\mu$"), type="l",xlab="t")
lines(rep(mu, tmax+1), col="red")
plot(rowMeans(thetas2[,,2]), ylab=TeX("$\\sigma^2$"), type="l",xlab="t")
lines(rep(sigma, tmax+1), col="red")
dev.off()
```
We can see that the algorithm does a very poor job of estimating both $\mu$ and $\sigma^2$ together, so we opt to ignore this implementation when considering the final filtering step and use only the single parameter version

Now to run the bootstrap filter, we use the population of thetas at the final step to get the estimate for the parameters $\mu$ and $\sigma$ to use in the final state estimation step.
```{r, params}
mut = sum(Wm[tmax+1,] * thetas[tmax+1,])/sum(Wm[tmax+1,])
mut2 = sum(Wm2[tmax+1,] * thetas2[tmax+1,,1])/sum(Wm2[tmax+1,])
sigma_t2 = sum(Wm2[tmax+1,] * thetas2[tmax+1,,2])/sum(Wm2[tmax+1,])
```

Plot the output from the final bootstrap particle filter, using just $\mu$ estimated using SMC^2.
```{r, bpf2}
boot_sv_smc2 <- new(Bootstrap_SV_C, Yt, mut, 0.15, 0.95)
output_smc2 <- bootstrap_filter_rcpp(boot_sv_smc2, N ,tmax)

pdf("docs/figs/state_estimation_smc2.pdf", width=8, height=3)
par(mar=c(4,4,1,4))
par(mfrow = c(1,2))
plot(Xt, type = "l", ylab=TeX("$X_t$"),xlab="t")
lines(output_smc2$mx, col = "red")
dev.off()
```

Plot the output from the final bootstrap particle filter, using both parameters estimated using SMC^2.
```{r, bpf22}
boot_sv_smc2 <- new(Bootstrap_SV_C, Yt, mut2, sigma_t2, 0.95)
output_smc2 <- bootstrap_filter_rcpp(boot_sv_smc2, N ,tmax)

pdf("docs/figs/state_estimation_smc22.pdf", width=8, height=3)
par(mar=c(4,4,1,4))
par(mfrow = c(1,2))
plot(Xt, type = "l", ylab=TeX("$X_t$"),xlab="t")
lines(output_smc2$mx, col = "red")
dev.off()
```